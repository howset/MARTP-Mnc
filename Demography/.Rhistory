data("iris")
set.seed(2021)
iris=iris[sample(1:nrow(iris)),] # shuffle data
Y <- as.numeric(iris$Species)-1
X <- as.matrix(subset(iris,select=c("Sepal.Length","Sepal.Width","Petal.Length","Petal.Width")))
Nobs <- nrow(iris) # number of observations
Nvar <- 4       # number of variables
# create training and independent test set
set <- sample(2,Nobs,replace=TRUE,prob = c(0.7,0.3))
trainingX <- X[set==1,]
trainingY <- Y[set==1]
trainingN <- length(trainingY)
testX <- X[set==2,]
testY <- Y[set==2]
testN <- length(testY)
# one-hot encoding of output variable (needs to be of type numerical=integer):
trainingY <- to_categorical(trainingY,num_classes=3) # 3 for species
testYOrig <- testY # keep original for table
testY <- to_categorical(testY,num_classes=3)
# normalize training data and apply mean and sd to test data as well
meanValues <- apply(trainingX,2,mean)
sdValues <- apply(trainingX,2,sd)
for(i in 1:Nvar) {
trainingX[,i] <- scale(trainingX[,i],center=meanValues[i],scale = sdValues[i])
testX[,i] <- scale(testX[,i],center=meanValues[i],scale = sdValues[i])
}
model <- keras_model_sequential()
model()
model
model %>%
layer_dense(units = 4, activation = 'relu', input_shape = c(Nvar)) %>%
layer_dense(units = 4, activation = 'relu') %>%
layer_dense(units = 3, activation = 'softmax')
model
model %>% compile(
loss = 'categorical_crossentropy',
optimizer = 'adam',
# optimizer = 'sgd',
metrics = c('accuracy')
)
history <- model %>% fit(
trainingX,trainingY, # now, trainingY is one-hot encoded!
epochs = 400,
batch_size = 32,
validation_split=0.2)
history
plot(history)
# apply to independent test dataset
model %>% evaluate(testX,testY)
prob <-model %>% predict_proba(testX)         # probabilities
predClass <- model %>% predict_classes(testX) # binary class calls
# confusion table
print(table(predicted=predClass,actual=testYOrig))
model
save_model_*
model %>% save_model_tf("test")
list.files("test")
new_model <- load_model_tf("test")
summary(new_model)
install.packages("kerastuneR")
library(kerastuneR)
install.packages("shiny")
install.packages("kerastuneR")
install.packages("magick")
install.packages("magick")
install.packages("magick")
install.packages("kerastuneR")
x_data <- matrix(data = runif(500,0,1),nrow = 50,ncol = 5)
y_data <-  ifelse(runif(50,0,1) > 0.6, 1L,0L) %>% as.matrix()
x_data2 <- matrix(data = runif(500,0,1),nrow = 50,ncol = 5)
y_data2 <-  ifelse(runif(50,0,1) > 0.6, 1L,0L) %>% as.matrix()
library(keras)
library(kerastuneR)
library(kerastuner)
library(kerastuneR)
use_condaenv("r-reticulate")
library(kerastuneR)
library(dplyr)
use_condaenv("base")
library(kerastuneR)
devtools::install_github('henry090/kerastuneR')
library(kerastuneR)
kerastuneR::install_kerastuner(python_path = '/usr/lib/python3.8')
library(kerastuneR)
kerastuneR::install_kerastuner(python_path = '/usr/lib/python3.8')
r-reticulate
use_condaenv("r-reticulate")
library(kerastuneR)
use_condaenv("r-tensorflow")
library(kerastuneR)
model <- keras_model_sequential()
model %>%
layer_dense(units = 4, activation = 'relu', input_shape = c(Nvar)) %>%
layer_dense(units = 4, activation = 'relu') %>%
layer_dense(units = 3, activation = 'softmax')
model %>% compile(
loss = 'categorical_crossentropy',
# optimizer = 'adam',
optimizer = 'sgd',
metrics = c('accuracy')
)
history <- model %>% fit(
trainingX,trainingY, # now, trainingY is one-hot encoded!
epochs = 1000,
batch_size = 32,
validation_split=0.2)
set.seed(2021)
iris=iris[sample(1:nrow(iris)),] # shuffle data
Y <- as.numeric(iris$Species)-1
X <- as.matrix(subset(iris,select=c("Sepal.Length","Sepal.Width","Petal.Length","Petal.Width")))
Nobs <- nrow(iris) # number of observations
Nvar <- 4       # number of variables
# create training and independent test set
set <- sample(2,Nobs,replace=TRUE,prob = c(0.7,0.3))
trainingX <- X[set==1,]
trainingY <- Y[set==1]
trainingN <- length(trainingY)
testX <- X[set==2,]
testY <- Y[set==2]
testN <- length(testY)
# one-hot encoding of output variable (needs to be of type numerical=integer):
trainingY <- to_categorical(trainingY,num_classes=3) # 3 for species
testYOrig <- testY # keep original for table
testY <- to_categorical(testY,num_classes=3)
# normalize training data and apply mean and sd to test data as well
meanValues <- apply(trainingX,2,mean)
sdValues <- apply(trainingX,2,sd)
for(i in 1:Nvar) {
trainingX[,i] <- scale(trainingX[,i],center=meanValues[i],scale = sdValues[i])
testX[,i] <- scale(testX[,i],center=meanValues[i],scale = sdValues[i])
}
model <- keras_model_sequential()
model %>%
layer_dense(units = 4, activation = 'relu', input_shape = c(Nvar)) %>%
layer_dense(units = 4, activation = 'relu') %>%
layer_dense(units = 3, activation = 'softmax')
model %>% compile(
loss = 'categorical_crossentropy',
# optimizer = 'adam',
optimizer = 'sgd',
metrics = c('accuracy')
)
history <- model %>% fit(
trainingX,trainingY, # now, trainingY is one-hot encoded!
epochs = 1000,
batch_size = 32,
validation_split=0.2)
history
plot(history)
model %>% evaluate(testX,testY)
prob <-model %>% predict_proba(testX)         # probabilities
predClass <- model %>% predict_classes(testX) # binary class calls
# confusion table
print(table(predicted=predClass,actual=testYOrig))
sm <- data.frame(Pos_news=c(39.5,31.57,37.5,43,44,42.85,31.42,31.48,32.53,30.26,27.39,22.53,29.62,31.91,17.24,45.61,32.2),
Surv=c(69,63,73,63,72,69,66,66,69,72,74,70,67,75,57,72,74))
sm2 <- sm[-15,]
sm <- data.frame(Pos_news=c(39.5,31.57,37.5,43,44,42.85,31.42,31.48,32.53,30.26,27.39,22.53,29.62,31.91,17.24,45.61,32.2),
Surv=c(69,63,73,63,72,69,66,66,69,72,74,70,67,75,57,72,74))
sm2 <- sm[-15,]
lm_eq <- function(df){
m <- lm(Surv ~ Pos_news, df);
corr <- cor.test(df$Surv,df$Pos_news)
eq <- substitute(~~Correlation~'='~c *','~~pval~'='~p, #only corr, no regression
list(c = format(unname(corr$estimate), digits = 3),
p = format(corr$p.value, digits = 3)))
as.character(as.expression(eq))
}
dat <- sm2
fluoplot <- ggplot(data = dat, mapping = aes(x = Pos_news, y = Surv)) +
geom_point(shape=1,color='#5e81ac') +
geom_smooth(method = "lm", data = dat, se=FALSE,color='#bf616a') + # to add trendline
stat_ellipse(color = 2,
linetype = 2,
lwd = 1.2)
f <- fluoplot +
annotate("text", x = 33, y = 45, label = lm_eq(dat), parse = TRUE) + #to show equation
ggtitle('SMRC_rem') +
xlab('Positive News (%)')+
ylab('Survey (%)')
print(f)
library(ggplot2)
lm_eq <- function(df){
m <- lm(Surv ~ Pos_news, df);
corr <- cor.test(df$Surv,df$Pos_news)
eq <- substitute(~~Correlation~'='~c *','~~pval~'='~p, #only corr, no regression
list(c = format(unname(corr$estimate), digits = 3),
p = format(corr$p.value, digits = 3)))
as.character(as.expression(eq))
}
dat <- sm2
fluoplot <- ggplot(data = dat, mapping = aes(x = Pos_news, y = Surv)) +
geom_point(shape=1,color='#5e81ac') +
geom_smooth(method = "lm", data = dat, se=FALSE,color='#bf616a') + # to add trendline
stat_ellipse(color = 2,
linetype = 2,
lwd = 1.2)
f <- fluoplot +
annotate("text", x = 33, y = 45, label = lm_eq(dat), parse = TRUE) + #to show equation
ggtitle('SMRC_rem') +
xlab('Positive News (%)')+
ylab('Survey (%)')
print(f)
lm_eq <- function(df){
m <- lm(Surv ~ Pos_news, df);
corr <- cor.test(df$Surv,df$Pos_news)
eq <- substitute(~~Correlation~'='~c *','~~pval~'='~p, #only corr, no regression
list(c = format(unname(corr$estimate), digits = 3),
p = format(corr$p.value, digits = 3)))
as.character(as.expression(eq))
}
dat <- sm2
fluoplot <- ggplot(data = dat, mapping = aes(x = Pos_news, y = Surv)) +
geom_point(shape=1,color='#5e81ac') +
geom_smooth(method = "lm", data = dat, se=FALSE,color='#bf616a',linetype=2) + # to add trendline
geom_smooth(method = "lm", data = sm, se=FALSE,color='5e81ac',linetype=1) + # to add trendline
stat_ellipse(color = 2,
linetype = 2,
lwd = 1.2)
f <- fluoplot +
annotate("text", x = 33, y = 45, label = lm_eq(dat), parse = TRUE) + #to show equation
ggtitle('SMRC_rem') +
xlab('Positive News (%)')+
ylab('Survey (%)')
print(f)
lm_eq <- function(df){
m <- lm(Surv ~ Pos_news, df);
corr <- cor.test(df$Surv,df$Pos_news)
eq <- substitute(~~Correlation~'='~c *','~~pval~'='~p, #only corr, no regression
list(c = format(unname(corr$estimate), digits = 3),
p = format(corr$p.value, digits = 3)))
as.character(as.expression(eq))
}
fluoplot <- ggplot(data = sm, mapping = aes(x = Pos_news, y = Surv)) +
geom_point(shape=1,color='#5e81ac') +
geom_smooth(method = "lm", data = sm2, se=FALSE,color='#bf616a',linetype=2) + # to add trendline
geom_smooth(method = "lm", data = sm, se=FALSE,color='#5e81ac',linetype=1) + # to add trendline
stat_ellipse(color = 2,
linetype = 2,
lwd = 1.2)
f <- fluoplot +
annotate("text", x = 33, y = 45, label = lm_eq(dat), parse = TRUE) + #to show equation
ggtitle('SMRC_rem') +
xlab('Positive News (%)')+
ylab('Survey (%)')
print(f)
lm_eq <- function(df){
m <- lm(Surv ~ Pos_news, df);
corr <- cor.test(df$Surv,df$Pos_news)
eq <- substitute(~~Correlation~'='~c *','~~pval~'='~p, #only corr, no regression
list(c = format(unname(corr$estimate), digits = 3),
p = format(corr$p.value, digits = 3)))
as.character(as.expression(eq))
}
fluoplot <- ggplot(data = sm, mapping = aes(x = Pos_news, y = Surv)) +
geom_point(shape=1,color='#5e81ac') +
geom_smooth(method = "lm", data = sm, se=FALSE,color='#5e81ac',linetype=1) + # to add trendline
stat_ellipse(color = 2,
linetype = 2,
lwd = 1.2) +
geom_smooth(method = "lm", data = sm2, se=FALSE,color='#bf616a',linetype=2)
f <- fluoplot +
annotate("text", x = 33, y = 45, label = lm_eq(dat), parse = TRUE) + #to show equation
ggtitle('SMRC_rem') +
xlab('Positive News (%)')+
ylab('Survey (%)')
print(f)
lm_eq <- function(df){
m <- lm(Surv ~ Pos_news, df);
corr <- cor.test(df$Surv,df$Pos_news)
eq <- substitute(~~Correlation~'='~c *','~~pval~'='~p, #only corr, no regression
list(c = format(unname(corr$estimate), digits = 3),
p = format(corr$p.value, digits = 3)))
as.character(as.expression(eq))
}
fluoplot <- ggplot(data = sm, mapping = aes(x = Pos_news, y = Surv)) +
geom_point(shape=1,color='#5e81ac') +
geom_smooth(method = "lm", data = sm, se=FALSE,color='#5e81ac',linetype=1) + # to add trendline
stat_ellipse(color = '#FFC000',
linetype = 2,
lwd = 1.2) +
geom_smooth(method = "lm", data = sm2, se=FALSE,color='#FFC000',linetype=1)
f <- fluoplot +
annotate("text", x = 33, y = 45, label = lm_eq(dat), parse = TRUE) + #to show equation
ggtitle('SMRC_rem') +
xlab('Positive News (%)')+
ylab('Survey (%)')
print(f)
setwd("~/workspace/MARTP-M")
agg_yg <- read.csv('Data/subset_indiv20210505.csv', header = TRUE)
agg_yg <- agg_yg[,-1] # remove first column
setwd("~/workspace/MARTP-M_2/Demography")
_
## Load and subset
agg_yg <- read.csv('Data/subset_indiv20210505.csv', header = TRUE)
agg_yg <- read.csv('Data/subset_indiv20210505.csv', header = TRUE)
agg_yg <- agg_yg[,-1] # remove first column
idtf <- agg_yg[,1]!=' ' # index of rows with empty qweek
agg_yg <- agg_yg[idtf,] # remove those rows
## Deal with columns columns
agg_yg$qweek <- as.factor(agg_yg$qweek)
agg_yg$qweek <- factor(agg_yg$qweek,levels(agg_yg$qweek)[c(4:9,1:3)])
agg_yg$gender <- as.factor(agg_yg$gender)
for (wcr in 1:length(agg_yg$region)) {
if (grepl('ava',agg_yg$region[wcr]) | grepl('karta',agg_yg$region[wcr]) ) {
agg_yg$region[wcr] <- 'Java'
} else {
agg_yg$region[wcr] <- 'Not Java'
}
}
agg_yg$region <- as.factor(agg_yg$region)
for (wcr in 1:length(agg_yg$employment_status)) {
if (agg_yg$employment_status[wcr]=='Full time employment' | agg_yg$employment_status[wcr]=='Part time employment' ) {
agg_yg$employment_status[wcr] <- 'Income'
} else  {
agg_yg$employment_status[wcr] <- 'No income'
}
}
reg <- ftable(agg_yg[c('qweek','region','WCRex1')]) # make contingency table
reg <- prop.table(reg,margin = 1) # proportions by row
reg <- as.data.frame(reg) # make data frame
r <- ggplot(reg,aes(x=qweek,y=Freq,fill=WCRex1)) +
geom_col() +
theme_linedraw() +
scale_fill_manual(values=c('#5992DB', '#FFC000')) +
ggtitle('By Java') + ylab('Proportion') + xlab('Survey week')
r + facet_grid(region ~ .)
## Library
library(ggplot2)
library(dplyr)
reg <- ftable(agg_yg[c('qweek','region','WCRex1')]) # make contingency table
reg <- prop.table(reg,margin = 1) # proportions by row
reg <- as.data.frame(reg) # make data frame
r <- ggplot(reg,aes(x=qweek,y=Freq,fill=WCRex1)) +
geom_col() +
theme_linedraw() +
scale_fill_manual(values=c('#5992DB', '#FFC000')) +
ggtitle('By Java') + ylab('Proportion') + xlab('Survey week')
r + facet_grid(region ~ .)
for (wcr in 1:length(agg_yg$WCRex1)) {
if (agg_yg$WCRex1[wcr]=='Somewhat well' | agg_yg$WCRex1[wcr]=='Very well' ) {
agg_yg$WCRex1[wcr] <- 'Favourably'
} else  {
agg_yg$WCRex1[wcr] <- 'Not favourably'
}
}
reg <- ftable(agg_yg[c('qweek','region','WCRex1')]) # make contingency table
reg <- prop.table(reg,margin = 1) # proportions by row
reg <- as.data.frame(reg) # make data frame
r <- ggplot(reg,aes(x=qweek,y=Freq,fill=WCRex1)) +
geom_col() +
theme_linedraw() +
scale_fill_manual(values=c('#5992DB', '#FFC000')) +
ggtitle('By Java') + ylab('Proportion') + xlab('Survey week')
r + facet_grid(region ~ .)
reg <- ftable(agg_yg[c('qweek','region','WCRex1')]) # make contingency table
reg <- prop.table(reg,margin = 1) # proportions by row
reg <- as.data.frame(reg) # make data frame
r <- ggplot(reg,aes(x=qweek,y=Freq,fill=WCRex1)) +
geom_col() +
theme_linedraw() +
scale_fill_manual(values=c('#5992DB', '#FFC000')) +
ggtitle('By Java') + ylab('Proportion') + xlab('Survey week')
r + facet_grid(region ~ .)
for (wcr in 1:length(agg_yg$region)) {
if (grepl('ava',agg_yg$region[wcr])  ) {
agg_yg$region[wcr] <- 'Java'
} else if (grepl('jakarta',agg_yg$region[wcr])) {
agg_yg$region[wcr] <- 'Jakarta'
}else {
agg_yg$region[wcr] <- 'Not Java'
}
}
agg_yg$region <- as.factor(agg_yg$region)
for (wcr in 1:length(agg_yg$region)) {
if (grepl('ava',agg_yg$region[wcr])  ) {
agg_yg$region[wcr] <- 'Java'
} else if (grepl('Jakarta',agg_yg$region[wcr])) {
agg_yg$region[wcr] <- 'Jakarta'
}else {
agg_yg$region[wcr] <- 'Not Java'
}
}
agg_yg$region <- as.factor(agg_yg$region)
reg <- ftable(agg_yg[c('qweek','region','WCRex1')]) # make contingency table
reg <- prop.table(reg,margin = 1) # proportions by row
reg <- as.data.frame(reg) # make data frame
r <- ggplot(reg,aes(x=qweek,y=Freq,fill=WCRex1)) +
geom_col() +
theme_linedraw() +
scale_fill_manual(values=c('#5992DB', '#FFC000')) +
ggtitle('By Java') + ylab('Proportion') + xlab('Survey week')
r + facet_grid(region ~ .)
agg_yg <- read.csv('Data/subset_indiv20210505.csv', header = TRUE)
agg_yg <- agg_yg[,-1] # remove first column
idtf <- agg_yg[,1]!=' ' # index of rows with empty qweek
agg_yg <- agg_yg[idtf,] # remove those rows
## Deal with columns columns
agg_yg$qweek <- as.factor(agg_yg$qweek)
agg_yg$qweek <- factor(agg_yg$qweek,levels(agg_yg$qweek)[c(4:9,1:3)])
agg_yg$gender <- as.factor(agg_yg$gender)
for (wcr in 1:length(agg_yg$region)) {
if (grepl('ava',agg_yg$region[wcr])  ) {
agg_yg$region[wcr] <- 'Java'
} else if (grepl('Jakarta',agg_yg$region[wcr])) {
agg_yg$region[wcr] <- 'Jakarta'
}else {
agg_yg$region[wcr] <- 'Not Java'
}
}
unique(agg_yg$region)
agg_yg$region <- as.factor(agg_yg$region)
reg <- ftable(agg_yg[c('qweek','region','WCRex1')]) # make contingency table
reg <- prop.table(reg,margin = 1) # proportions by row
reg <- as.data.frame(reg) # make data frame
r <- ggplot(reg,aes(x=qweek,y=Freq,fill=WCRex1)) +
geom_col() +
theme_linedraw() +
scale_fill_manual(values=c('#5992DB', '#FFC000')) +
ggtitle('By Java') + ylab('Proportion') + xlab('Survey week')
r + facet_grid(region ~ .)
r <- ggplot(reg,aes(x=qweek,y=Freq,fill=WCRex1)) +
geom_col() +
theme_linedraw() +
#scale_fill_manual(values=c('#5992DB', '#FFC000')) +
ggtitle('By Java') + ylab('Proportion') + xlab('Survey week')
r + facet_grid(region ~ .)
for (wcr in 1:length(agg_yg$employment_status)) {
if (agg_yg$employment_status[wcr]=='Full time employment' | agg_yg$employment_status[wcr]=='Part time employment' ) {
agg_yg$employment_status[wcr] <- 'Income'
} else  {
agg_yg$employment_status[wcr] <- 'No income'
}
}
reg <- ftable(agg_yg[c('qweek','region','WCRex1')]) # make contingency table
reg <- prop.table(reg,margin = 1) # proportions by row
reg <- as.data.frame(reg) # make data frame
r <- ggplot(reg,aes(x=qweek,y=Freq,fill=WCRex1)) +
geom_col() +
theme_linedraw() +
scale_fill_manual(values=c('#5992DB', '#FFC000')) +
ggtitle('By Java') + ylab('Proportion') + xlab('Survey week')
r + facet_grid(region ~ .)
agg_yg <- read.csv('Data/subset_indiv20210505.csv', header = TRUE)
agg_yg <- agg_yg[,-1] # remove first column
idtf <- agg_yg[,1]!=' ' # index of rows with empty qweek
agg_yg <- agg_yg[idtf,] # remove those rows
## Deal with columns columns
agg_yg$qweek <- as.factor(agg_yg$qweek)
agg_yg$qweek <- factor(agg_yg$qweek,levels(agg_yg$qweek)[c(4:9,1:3)])
agg_yg$gender <- as.factor(agg_yg$gender)
for (wcr in 1:length(agg_yg$region)) {
if (grepl('ava',agg_yg$region[wcr])  ) {
agg_yg$region[wcr] <- 'Java'
} else if (grepl('Jakarta',agg_yg$region[wcr])) {
agg_yg$region[wcr] <- 'Jakarta'
}else {
agg_yg$region[wcr] <- 'Not Java'
}
}
agg_yg$region <- as.factor(agg_yg$region)
for (wcr in 1:length(agg_yg$employment_status)) {
if (agg_yg$employment_status[wcr]=='Full time employment' | agg_yg$employment_status[wcr]=='Part time employment' ) {
agg_yg$employment_status[wcr] <- 'Income'
} else  {
agg_yg$employment_status[wcr] <- 'No income'
}
}
agg_yg$employment_status <- as.factor(agg_yg$employment_status)
for (wcr in 1:length(agg_yg$WCRex1)) {
if (agg_yg$WCRex1[wcr]=='Somewhat well' | agg_yg$WCRex1[wcr]=='Very well' ) {
agg_yg$WCRex1[wcr] <- 'Favourably'
} else  {
agg_yg$WCRex1[wcr] <- 'Not favourably'
}
}
reg <- ftable(agg_yg[c('qweek','region','WCRex1')]) # make contingency table
reg <- prop.table(reg,margin = 1) # proportions by row
reg <- as.data.frame(reg) # make data frame
r <- ggplot(reg,aes(x=qweek,y=Freq,fill=WCRex1)) +
geom_col() +
theme_linedraw() +
scale_fill_manual(values=c('#5992DB', '#FFC000')) +
ggtitle('By Java') + ylab('Proportion') + xlab('Survey week')
r + facet_grid(region ~ .)
emp <- ftable(agg_yg[c('qweek','employment_status','WCRex1')])
emp <- prop.table(emp,margin = 1) # proportions by row
emp <- as.data.frame(emp) # make data frame
e <- ggplot(emp,aes(x=qweek,y=Freq,fill=WCRex1)) +
geom_col() +
theme_linedraw() +
scale_fill_manual(values=c('#5992DB', '#FFC000')) +
ggtitle('By Income') + ylab('Proportion') + xlab('Survey week')
e + facet_grid(employment_status ~ .)
hsize <- ftable(agg_yg[c('qweek','household_size','WCRex1')])
hsize <- prop.table(hsize,margin = 1) # proportions by row
hsize <- as.data.frame(hsize) # make data frame
hs <- ggplot(hsize,aes(x=qweek,y=Freq,fill=WCRex1)) +
geom_col() +
theme_linedraw() +
scale_fill_manual(values=c('#5992DB', '#FFC000')) +
ggtitle('By Income') + ylab('Proportion') + xlab('Survey week')
hs + facet_grid(household_size ~ .)
gen <- ftable(agg_yg[c('qweek','gender','WCRex1')]) # make contingency table
gen <- prop.table(gen,margin = 1) # proportions by row
gen <- as.data.frame(gen) # make data frame
g <- ggplot(gen,aes(x=qweek,y=Freq,fill=WCRex1)) +
geom_col() +
theme_linedraw() +
scale_fill_manual(values=c('#5992DB', '#FFC000')) +
ggtitle('By gender') + ylab('Proportion') + xlab('Survey week')
g + facet_grid(gender ~ .)
